{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "public-leadership",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(path):\n",
    "    pose_info = pickle.load(open(Path(str(path)), \"rb\" ))\n",
    "    ans = []\n",
    "    frame_length = len(pose_info)\n",
    "    strat_frame = 0\n",
    "    if frame_length <23:\n",
    "        start_frame = 13\n",
    "    elif frame_length<28:\n",
    "        start_frame = 18\n",
    "    else:\n",
    "        start_frame = 20\n",
    "    \n",
    "    for i in range(5):\n",
    "        pose = pose_info[start_frame+i]\n",
    "        for j in joints:\n",
    "            if j in pose.body_parts:\n",
    "                ans.append(pose.body_parts.get(j).x)\n",
    "                ans.append(pose.body_parts.get(j).y)\n",
    "            else:\n",
    "                ans.append(0)\n",
    "                ans.append(0)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "extensive-linux",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle \n",
    "from pathlib import Path\n",
    "import statistics \n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "path = '/home/chandu/Desktop/Pose Estimation/tf-pose-estimation/output/normalized/six/'\n",
    "out_path = '/home/chandu/Desktop/Pose Estimation/tf-pose-estimation/output/data/six/'\n",
    "joints = [0,1,2,3,4,5,6,7,8,9,10,11,12,13]\n",
    "paths = sorted(Path(path).iterdir(), key=os.path.getmtime)\n",
    "\n",
    "total_data = []\n",
    "for i in range(len(paths)):\n",
    "    if str(paths[i]).split('/')[-1].split('.')[0].split('_')[-1] != 'error':\n",
    "        arr = prepare(paths[i])\n",
    "        num = 'six'+str(paths[i]).split('/')[-1].split('.')[0].split('_')[-1]\n",
    "        arr.append(num)\n",
    "        arr.append(1)\n",
    "        total_data.append(arr)\n",
    "        \n",
    "six = pd.DataFrame(data = total_data)\n",
    "\n",
    "total_data = []\n",
    "path = '/home/chandu/Desktop/Pose Estimation/tf-pose-estimation/output/normalized/out/'\n",
    "out_path = '/home/chandu/Desktop/Pose Estimation/tf-pose-estimation/output/data/out/'\n",
    "paths = sorted(Path(path).iterdir(), key=os.path.getmtime)\n",
    "for i in range(len(paths)):\n",
    "    if str(paths[i]).split('/')[-1].split('.')[0].split('_')[-1] != 'error':\n",
    "        arr = prepare(paths[i])\n",
    "        num = 'out'+str(paths[i]).split('/')[-1].split('.')[0].split('_')[-1]\n",
    "        arr.append(num)\n",
    "        arr.append(0)\n",
    "        total_data.append(arr)\n",
    "path = '/home/chandu/Desktop/Pose Estimation/tf-pose-estimation/output/normalized/misshit/'\n",
    "out_path = '/home/chandu/Desktop/Pose Estimation/tf-pose-estimation/output/data/misshit/'\n",
    "paths = sorted(Path(path).iterdir(), key=os.path.getmtime)\n",
    "for i in range(len(paths)):\n",
    "    if str(paths[i]).split('/')[-1].split('.')[0].split('_')[-1] != 'error':\n",
    "        arr = prepare(paths[i])\n",
    "        num = 'miss'+str(paths[i]).split('/')[-1].split('.')[0].split('_')[-1]\n",
    "        arr.append(num)\n",
    "        arr.append(0)\n",
    "        total_data.append(arr)\n",
    "\n",
    "out = pd.DataFrame(data=total_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "commercial-killer",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_info = pickle.load(open(Path(str(paths[0])), \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "exempt-somewhere",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prepare(paths[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "relevant-klein",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.493931</td>\n",
       "      <td>0.372700</td>\n",
       "      <td>0.481183</td>\n",
       "      <td>0.377688</td>\n",
       "      <td>0.484370</td>\n",
       "      <td>0.394315</td>\n",
       "      <td>0.489947</td>\n",
       "      <td>0.429231</td>\n",
       "      <td>0.493134</td>\n",
       "      <td>0.410942</td>\n",
       "      <td>...</td>\n",
       "      <td>0.457509</td>\n",
       "      <td>0.617061</td>\n",
       "      <td>0.453565</td>\n",
       "      <td>0.500706</td>\n",
       "      <td>0.457509</td>\n",
       "      <td>0.543574</td>\n",
       "      <td>0.456852</td>\n",
       "      <td>0.578786</td>\n",
       "      <td>six0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.488718</td>\n",
       "      <td>0.481869</td>\n",
       "      <td>0.495152</td>\n",
       "      <td>0.494127</td>\n",
       "      <td>0.485041</td>\n",
       "      <td>0.501788</td>\n",
       "      <td>0.482284</td>\n",
       "      <td>0.530901</td>\n",
       "      <td>0.495152</td>\n",
       "      <td>0.509449</td>\n",
       "      <td>...</td>\n",
       "      <td>0.505898</td>\n",
       "      <td>0.685171</td>\n",
       "      <td>0.508209</td>\n",
       "      <td>0.557637</td>\n",
       "      <td>0.508979</td>\n",
       "      <td>0.609692</td>\n",
       "      <td>0.506668</td>\n",
       "      <td>0.686473</td>\n",
       "      <td>six3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.517187</td>\n",
       "      <td>0.411800</td>\n",
       "      <td>0.503298</td>\n",
       "      <td>0.420702</td>\n",
       "      <td>0.506771</td>\n",
       "      <td>0.433164</td>\n",
       "      <td>0.517187</td>\n",
       "      <td>0.458089</td>\n",
       "      <td>0.523264</td>\n",
       "      <td>0.452748</td>\n",
       "      <td>...</td>\n",
       "      <td>0.482944</td>\n",
       "      <td>0.600244</td>\n",
       "      <td>0.487157</td>\n",
       "      <td>0.498986</td>\n",
       "      <td>0.487860</td>\n",
       "      <td>0.539489</td>\n",
       "      <td>0.490669</td>\n",
       "      <td>0.589339</td>\n",
       "      <td>six1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.449422</td>\n",
       "      <td>0.417569</td>\n",
       "      <td>0.459910</td>\n",
       "      <td>0.430208</td>\n",
       "      <td>0.453917</td>\n",
       "      <td>0.442847</td>\n",
       "      <td>0.454666</td>\n",
       "      <td>0.475347</td>\n",
       "      <td>0.454666</td>\n",
       "      <td>0.493403</td>\n",
       "      <td>...</td>\n",
       "      <td>0.474788</td>\n",
       "      <td>0.669872</td>\n",
       "      <td>0.481222</td>\n",
       "      <td>0.547222</td>\n",
       "      <td>0.481937</td>\n",
       "      <td>0.610043</td>\n",
       "      <td>0.474073</td>\n",
       "      <td>0.677351</td>\n",
       "      <td>six2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.473265</td>\n",
       "      <td>0.416087</td>\n",
       "      <td>0.475839</td>\n",
       "      <td>0.424951</td>\n",
       "      <td>0.467258</td>\n",
       "      <td>0.436770</td>\n",
       "      <td>0.483562</td>\n",
       "      <td>0.433815</td>\n",
       "      <td>0.498149</td>\n",
       "      <td>0.413132</td>\n",
       "      <td>...</td>\n",
       "      <td>0.479022</td>\n",
       "      <td>0.583256</td>\n",
       "      <td>0.496197</td>\n",
       "      <td>0.493616</td>\n",
       "      <td>0.496197</td>\n",
       "      <td>0.542918</td>\n",
       "      <td>0.492108</td>\n",
       "      <td>0.592220</td>\n",
       "      <td>six6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>0.462203</td>\n",
       "      <td>0.417511</td>\n",
       "      <td>0.454984</td>\n",
       "      <td>0.436193</td>\n",
       "      <td>0.446734</td>\n",
       "      <td>0.439067</td>\n",
       "      <td>0.448797</td>\n",
       "      <td>0.466372</td>\n",
       "      <td>0.463234</td>\n",
       "      <td>0.447690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.405235</td>\n",
       "      <td>0.636111</td>\n",
       "      <td>0.432735</td>\n",
       "      <td>0.544445</td>\n",
       "      <td>0.438360</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>0.429610</td>\n",
       "      <td>0.637500</td>\n",
       "      <td>six460</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>0.456734</td>\n",
       "      <td>0.390440</td>\n",
       "      <td>0.464308</td>\n",
       "      <td>0.403013</td>\n",
       "      <td>0.458799</td>\n",
       "      <td>0.397425</td>\n",
       "      <td>0.448471</td>\n",
       "      <td>0.411395</td>\n",
       "      <td>0.436077</td>\n",
       "      <td>0.414189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463292</td>\n",
       "      <td>0.595021</td>\n",
       "      <td>0.484839</td>\n",
       "      <td>0.494804</td>\n",
       "      <td>0.488879</td>\n",
       "      <td>0.544912</td>\n",
       "      <td>0.508406</td>\n",
       "      <td>0.581037</td>\n",
       "      <td>six463</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>0.497060</td>\n",
       "      <td>0.345878</td>\n",
       "      <td>0.511860</td>\n",
       "      <td>0.350078</td>\n",
       "      <td>0.514635</td>\n",
       "      <td>0.341678</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.525611</td>\n",
       "      <td>0.576982</td>\n",
       "      <td>0.545720</td>\n",
       "      <td>0.444774</td>\n",
       "      <td>0.538179</td>\n",
       "      <td>0.521416</td>\n",
       "      <td>0.532314</td>\n",
       "      <td>0.594226</td>\n",
       "      <td>six464</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>0.471672</td>\n",
       "      <td>0.479114</td>\n",
       "      <td>0.476552</td>\n",
       "      <td>0.472180</td>\n",
       "      <td>0.470045</td>\n",
       "      <td>0.489515</td>\n",
       "      <td>0.483059</td>\n",
       "      <td>0.515518</td>\n",
       "      <td>0.480619</td>\n",
       "      <td>0.506850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509739</td>\n",
       "      <td>0.618784</td>\n",
       "      <td>0.495328</td>\n",
       "      <td>0.538652</td>\n",
       "      <td>0.491869</td>\n",
       "      <td>0.599102</td>\n",
       "      <td>0.492445</td>\n",
       "      <td>0.656741</td>\n",
       "      <td>six465</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>0.513315</td>\n",
       "      <td>0.338672</td>\n",
       "      <td>0.526721</td>\n",
       "      <td>0.341537</td>\n",
       "      <td>0.527559</td>\n",
       "      <td>0.334374</td>\n",
       "      <td>0.542640</td>\n",
       "      <td>0.338672</td>\n",
       "      <td>0.540127</td>\n",
       "      <td>0.342970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.549943</td>\n",
       "      <td>0.586100</td>\n",
       "      <td>0.561929</td>\n",
       "      <td>0.450716</td>\n",
       "      <td>0.558403</td>\n",
       "      <td>0.523024</td>\n",
       "      <td>0.552763</td>\n",
       "      <td>0.593793</td>\n",
       "      <td>six466</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>463 rows × 142 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0    0.493931  0.372700  0.481183  0.377688  0.484370  0.394315  0.489947   \n",
       "1    0.488718  0.481869  0.495152  0.494127  0.485041  0.501788  0.482284   \n",
       "2    0.517187  0.411800  0.503298  0.420702  0.506771  0.433164  0.517187   \n",
       "3    0.449422  0.417569  0.459910  0.430208  0.453917  0.442847  0.454666   \n",
       "4    0.473265  0.416087  0.475839  0.424951  0.467258  0.436770  0.483562   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "458  0.462203  0.417511  0.454984  0.436193  0.446734  0.439067  0.448797   \n",
       "459  0.456734  0.390440  0.464308  0.403013  0.458799  0.397425  0.448471   \n",
       "460  0.497060  0.345878  0.511860  0.350078  0.514635  0.341678  0.000000   \n",
       "461  0.471672  0.479114  0.476552  0.472180  0.470045  0.489515  0.483059   \n",
       "462  0.513315  0.338672  0.526721  0.341537  0.527559  0.334374  0.542640   \n",
       "\n",
       "          7         8         9    ...       132       133       134  \\\n",
       "0    0.429231  0.493134  0.410942  ...  0.457509  0.617061  0.453565   \n",
       "1    0.530901  0.495152  0.509449  ...  0.505898  0.685171  0.508209   \n",
       "2    0.458089  0.523264  0.452748  ...  0.482944  0.600244  0.487157   \n",
       "3    0.475347  0.454666  0.493403  ...  0.474788  0.669872  0.481222   \n",
       "4    0.433815  0.498149  0.413132  ...  0.479022  0.583256  0.496197   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "458  0.466372  0.463234  0.447690  ...  0.405235  0.636111  0.432735   \n",
       "459  0.411395  0.436077  0.414189  ...  0.463292  0.595021  0.484839   \n",
       "460  0.000000  0.000000  0.000000  ...  0.525611  0.576982  0.545720   \n",
       "461  0.515518  0.480619  0.506850  ...  0.509739  0.618784  0.495328   \n",
       "462  0.338672  0.540127  0.342970  ...  0.549943  0.586100  0.561929   \n",
       "\n",
       "          135       136       137       138       139     140  141  \n",
       "0    0.500706  0.457509  0.543574  0.456852  0.578786    six0    1  \n",
       "1    0.557637  0.508979  0.609692  0.506668  0.686473    six3    1  \n",
       "2    0.498986  0.487860  0.539489  0.490669  0.589339    six1    1  \n",
       "3    0.547222  0.481937  0.610043  0.474073  0.677351    six2    1  \n",
       "4    0.493616  0.496197  0.542918  0.492108  0.592220    six6    1  \n",
       "..        ...       ...       ...       ...       ...     ...  ...  \n",
       "458  0.544445  0.438360  0.591667  0.429610  0.637500  six460    1  \n",
       "459  0.494804  0.488879  0.544912  0.508406  0.581037  six463    1  \n",
       "460  0.444774  0.538179  0.521416  0.532314  0.594226  six464    1  \n",
       "461  0.538652  0.491869  0.599102  0.492445  0.656741  six465    1  \n",
       "462  0.450716  0.558403  0.523024  0.552763  0.593793  six466    1  \n",
       "\n",
       "[463 rows x 142 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ranging-intensity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.479895</td>\n",
       "      <td>0.392494</td>\n",
       "      <td>0.489864</td>\n",
       "      <td>0.408431</td>\n",
       "      <td>0.480726</td>\n",
       "      <td>0.413212</td>\n",
       "      <td>0.474911</td>\n",
       "      <td>0.440304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.509589</td>\n",
       "      <td>0.526063</td>\n",
       "      <td>0.517210</td>\n",
       "      <td>0.578481</td>\n",
       "      <td>0.512130</td>\n",
       "      <td>0.635392</td>\n",
       "      <td>out0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.511406</td>\n",
       "      <td>0.371437</td>\n",
       "      <td>0.520781</td>\n",
       "      <td>0.382307</td>\n",
       "      <td>0.512344</td>\n",
       "      <td>0.393176</td>\n",
       "      <td>0.517031</td>\n",
       "      <td>0.430133</td>\n",
       "      <td>0.510469</td>\n",
       "      <td>0.451872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517555</td>\n",
       "      <td>0.626167</td>\n",
       "      <td>0.551471</td>\n",
       "      <td>0.500661</td>\n",
       "      <td>0.565533</td>\n",
       "      <td>0.561389</td>\n",
       "      <td>0.568842</td>\n",
       "      <td>0.636288</td>\n",
       "      <td>out2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.475313</td>\n",
       "      <td>0.371581</td>\n",
       "      <td>0.492188</td>\n",
       "      <td>0.375427</td>\n",
       "      <td>0.484687</td>\n",
       "      <td>0.394658</td>\n",
       "      <td>0.494063</td>\n",
       "      <td>0.427350</td>\n",
       "      <td>0.493125</td>\n",
       "      <td>0.460043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>out1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.508303</td>\n",
       "      <td>0.412238</td>\n",
       "      <td>0.504703</td>\n",
       "      <td>0.431190</td>\n",
       "      <td>0.500203</td>\n",
       "      <td>0.431190</td>\n",
       "      <td>0.513703</td>\n",
       "      <td>0.424872</td>\n",
       "      <td>0.527203</td>\n",
       "      <td>0.415396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516712</td>\n",
       "      <td>0.666139</td>\n",
       "      <td>0.491033</td>\n",
       "      <td>0.561533</td>\n",
       "      <td>0.498981</td>\n",
       "      <td>0.621308</td>\n",
       "      <td>0.486142</td>\n",
       "      <td>0.667634</td>\n",
       "      <td>out5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.465820</td>\n",
       "      <td>0.486818</td>\n",
       "      <td>0.476562</td>\n",
       "      <td>0.488530</td>\n",
       "      <td>0.482422</td>\n",
       "      <td>0.517630</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.497089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.424439</td>\n",
       "      <td>0.726121</td>\n",
       "      <td>0.442651</td>\n",
       "      <td>0.626818</td>\n",
       "      <td>0.450101</td>\n",
       "      <td>0.679307</td>\n",
       "      <td>0.456724</td>\n",
       "      <td>0.730377</td>\n",
       "      <td>out3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>0.475848</td>\n",
       "      <td>0.414774</td>\n",
       "      <td>0.479405</td>\n",
       "      <td>0.435400</td>\n",
       "      <td>0.466069</td>\n",
       "      <td>0.436689</td>\n",
       "      <td>0.482961</td>\n",
       "      <td>0.436689</td>\n",
       "      <td>0.494518</td>\n",
       "      <td>0.418642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.479872</td>\n",
       "      <td>0.581959</td>\n",
       "      <td>0.492004</td>\n",
       "      <td>0.490165</td>\n",
       "      <td>0.495037</td>\n",
       "      <td>0.538247</td>\n",
       "      <td>0.489729</td>\n",
       "      <td>0.589608</td>\n",
       "      <td>miss143</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>0.498047</td>\n",
       "      <td>0.353036</td>\n",
       "      <td>0.503906</td>\n",
       "      <td>0.360086</td>\n",
       "      <td>0.493164</td>\n",
       "      <td>0.367136</td>\n",
       "      <td>0.489258</td>\n",
       "      <td>0.411197</td>\n",
       "      <td>0.485351</td>\n",
       "      <td>0.400623</td>\n",
       "      <td>...</td>\n",
       "      <td>0.505796</td>\n",
       "      <td>0.620557</td>\n",
       "      <td>0.516885</td>\n",
       "      <td>0.494897</td>\n",
       "      <td>0.523941</td>\n",
       "      <td>0.558433</td>\n",
       "      <td>0.517893</td>\n",
       "      <td>0.609262</td>\n",
       "      <td>miss148</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>0.482203</td>\n",
       "      <td>0.328931</td>\n",
       "      <td>0.476693</td>\n",
       "      <td>0.331117</td>\n",
       "      <td>0.464294</td>\n",
       "      <td>0.313629</td>\n",
       "      <td>0.447761</td>\n",
       "      <td>0.331117</td>\n",
       "      <td>0.456027</td>\n",
       "      <td>0.368279</td>\n",
       "      <td>...</td>\n",
       "      <td>0.436514</td>\n",
       "      <td>0.593329</td>\n",
       "      <td>0.449242</td>\n",
       "      <td>0.470387</td>\n",
       "      <td>0.449242</td>\n",
       "      <td>0.530941</td>\n",
       "      <td>0.452636</td>\n",
       "      <td>0.578649</td>\n",
       "      <td>miss149</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>0.494343</td>\n",
       "      <td>0.286372</td>\n",
       "      <td>0.494343</td>\n",
       "      <td>0.297726</td>\n",
       "      <td>0.481412</td>\n",
       "      <td>0.300969</td>\n",
       "      <td>0.472791</td>\n",
       "      <td>0.343139</td>\n",
       "      <td>0.469558</td>\n",
       "      <td>0.325298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.485925</td>\n",
       "      <td>0.548305</td>\n",
       "      <td>0.504367</td>\n",
       "      <td>0.446085</td>\n",
       "      <td>0.499244</td>\n",
       "      <td>0.502874</td>\n",
       "      <td>0.497195</td>\n",
       "      <td>0.560925</td>\n",
       "      <td>miss147</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>0.472443</td>\n",
       "      <td>0.336806</td>\n",
       "      <td>0.480114</td>\n",
       "      <td>0.340972</td>\n",
       "      <td>0.472443</td>\n",
       "      <td>0.351389</td>\n",
       "      <td>0.469034</td>\n",
       "      <td>0.386806</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.480349</td>\n",
       "      <td>0.557414</td>\n",
       "      <td>0.497176</td>\n",
       "      <td>0.429743</td>\n",
       "      <td>0.499579</td>\n",
       "      <td>0.503553</td>\n",
       "      <td>0.494772</td>\n",
       "      <td>0.577362</td>\n",
       "      <td>miss150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>379 rows × 142 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0    0.479895  0.392494  0.489864  0.408431  0.480726  0.413212  0.474911   \n",
       "1    0.511406  0.371437  0.520781  0.382307  0.512344  0.393176  0.517031   \n",
       "2    0.475313  0.371581  0.492188  0.375427  0.484687  0.394658  0.494063   \n",
       "3    0.508303  0.412238  0.504703  0.431190  0.500203  0.431190  0.513703   \n",
       "4    0.000000  0.000000  0.465820  0.486818  0.476562  0.488530  0.482422   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "374  0.475848  0.414774  0.479405  0.435400  0.466069  0.436689  0.482961   \n",
       "375  0.498047  0.353036  0.503906  0.360086  0.493164  0.367136  0.489258   \n",
       "376  0.482203  0.328931  0.476693  0.331117  0.464294  0.313629  0.447761   \n",
       "377  0.494343  0.286372  0.494343  0.297726  0.481412  0.300969  0.472791   \n",
       "378  0.472443  0.336806  0.480114  0.340972  0.472443  0.351389  0.469034   \n",
       "\n",
       "          7         8         9    ...       132       133       134  \\\n",
       "0    0.440304  0.000000  0.000000  ...  0.000000  0.000000  0.509589   \n",
       "1    0.430133  0.510469  0.451872  ...  0.517555  0.626167  0.551471   \n",
       "2    0.427350  0.493125  0.460043  ...  0.000000  0.000000  0.000000   \n",
       "3    0.424872  0.527203  0.415396  ...  0.516712  0.666139  0.491033   \n",
       "4    0.517630  0.488281  0.497089  ...  0.424439  0.726121  0.442651   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "374  0.436689  0.494518  0.418642  ...  0.479872  0.581959  0.492004   \n",
       "375  0.411197  0.485351  0.400623  ...  0.505796  0.620557  0.516885   \n",
       "376  0.331117  0.456027  0.368279  ...  0.436514  0.593329  0.449242   \n",
       "377  0.343139  0.469558  0.325298  ...  0.485925  0.548305  0.504367   \n",
       "378  0.386806  0.000000  0.000000  ...  0.480349  0.557414  0.497176   \n",
       "\n",
       "          135       136       137       138       139      140  141  \n",
       "0    0.526063  0.517210  0.578481  0.512130  0.635392     out0    0  \n",
       "1    0.500661  0.565533  0.561389  0.568842  0.636288     out2    0  \n",
       "2    0.000000  0.000000  0.000000  0.000000  0.000000     out1    0  \n",
       "3    0.561533  0.498981  0.621308  0.486142  0.667634     out5    0  \n",
       "4    0.626818  0.450101  0.679307  0.456724  0.730377     out3    0  \n",
       "..        ...       ...       ...       ...       ...      ...  ...  \n",
       "374  0.490165  0.495037  0.538247  0.489729  0.589608  miss143    0  \n",
       "375  0.494897  0.523941  0.558433  0.517893  0.609262  miss148    0  \n",
       "376  0.470387  0.449242  0.530941  0.452636  0.578649  miss149    0  \n",
       "377  0.446085  0.499244  0.502874  0.497195  0.560925  miss147    0  \n",
       "378  0.429743  0.499579  0.503553  0.494772  0.577362  miss150    0  \n",
       "\n",
       "[379 rows x 142 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "russian-diagnosis",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = six.append(out) #+ misshit\n",
    "\n",
    "X = total.drop([140,141], axis=1)\n",
    "y = total[141]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20,random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "covered-organ",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='linear')\n",
    "svclassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "endless-hepatitis",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svclassifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "frank-november",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11 62]\n",
      " [13 83]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.15      0.23        73\n",
      "           1       0.57      0.86      0.69        96\n",
      "\n",
      "    accuracy                           0.56       169\n",
      "   macro avg       0.52      0.51      0.46       169\n",
      "weighted avg       0.52      0.56      0.49       169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "interstate-documentary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200, random_state=107)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=200,random_state=107)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "occupational-absence",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "original-photography",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22 51]\n",
      " [29 67]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.30      0.35        73\n",
      "           1       0.57      0.70      0.63        96\n",
      "\n",
      "    accuracy                           0.53       169\n",
      "   macro avg       0.50      0.50      0.49       169\n",
      "weighted avg       0.51      0.53      0.51       169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "flush-saskatchewan",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chandu/anaconda3/envs/pose/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR = LogisticRegression()\n",
    "LR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "patent-portfolio",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = LR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "adjusted-pressing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14 59]\n",
      " [19 77]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.19      0.26        73\n",
      "           1       0.57      0.80      0.66        96\n",
      "\n",
      "    accuracy                           0.54       169\n",
      "   macro avg       0.50      0.50      0.46       169\n",
      "weighted avg       0.50      0.54      0.49       169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "leading-cabinet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='linear')\n",
    "svclassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "pleasant-canada",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svclassifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "wired-clothing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11 62]\n",
      " [13 83]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.15      0.23        73\n",
      "           1       0.57      0.86      0.69        96\n",
      "\n",
      "    accuracy                           0.56       169\n",
      "   macro avg       0.52      0.51      0.46       169\n",
      "weighted avg       0.52      0.56      0.49       169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "stunning-connecticut",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chandu/anaconda3/envs/pose/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR = LogisticRegression()\n",
    "LR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "regular-trace",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = LR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "inside-threshold",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14 59]\n",
      " [19 77]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.19      0.26        73\n",
      "           1       0.57      0.80      0.66        96\n",
      "\n",
      "    accuracy                           0.54       169\n",
      "   macro avg       0.50      0.50      0.46       169\n",
      "weighted avg       0.50      0.54      0.49       169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "nuclear-stations",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200, random_state=107)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=200,random_state=107)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "raised-africa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "creative-senior",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22 51]\n",
      " [29 67]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.30      0.35        73\n",
      "           1       0.57      0.70      0.63        96\n",
      "\n",
      "    accuracy                           0.53       169\n",
      "   macro avg       0.50      0.50      0.49       169\n",
      "weighted avg       0.51      0.53      0.51       169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-worse",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
